{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba9e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "report_dir = \"docs/reports/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e975062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "class GetDataset:\n",
    "    input_dir = \"\"\n",
    "\n",
    "    def __init__(self, input_dir, batch_size=32):\n",
    "        transform = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    "        )\n",
    "\n",
    "        train_valid_data = datasets.CIFAR10(\n",
    "            f\"{input_dir}/train\", train=True, download=True, transform=transform\n",
    "        )\n",
    "        test_dataset = datasets.CIFAR10(\n",
    "            f\"{input_dir}/test\", train=False, download=True, transform=transform\n",
    "        )\n",
    "\n",
    "        train_dataset, valid_dataset = random_split(train_valid_data, (45000, 5000))\n",
    "\n",
    "        print(\n",
    "            \"Image shape of a random sample image : {}\".format(\n",
    "                train_dataset[0][0].numpy().shape\n",
    "            ),\n",
    "            end=\"\\n\\n\",\n",
    "        )\n",
    "\n",
    "        print(\"Training Set:   {} images\".format(len(train_dataset)))\n",
    "        print(\"Validation Set:   {} images\".format(len(valid_dataset)))\n",
    "        print(\"Test Set:       {} images\".format(len(test_dataset)))\n",
    "\n",
    "        batch_size = 32\n",
    "\n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True\n",
    "        )\n",
    "        self.valid_loader = DataLoader(\n",
    "            valid_dataset, batch_size=batch_size, shuffle=True\n",
    "        )\n",
    "        self.test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        self.num_classes = len(train_valid_data.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407b6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, flatten\n",
    "\n",
    "\n",
    "class Auxiliary(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(Auxiliary, self).__init__()\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "        self.conv = nn.Conv2d(in_channels, 128, kernel_size=1, stride=1, padding=0)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.dropout = nn.Dropout(0.7)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool(x)\n",
    "        out = self.conv(out)\n",
    "        out = self.act(out)\n",
    "\n",
    "        out = flatten(out, 1)  # reshaping to one dim tensor\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = self.act(out)\n",
    "\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b7a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "# the starter convolutional block\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d8bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, cat\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        num1x1,\n",
    "        num3x3_reduce,\n",
    "        num3x3,\n",
    "        num5x5_reduce,\n",
    "        num5x5,\n",
    "        pool_proj,\n",
    "    ):\n",
    "        super(Inception, self).__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            ConvBlock(in_channels, num1x1, kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            ConvBlock(in_channels, num3x3_reduce, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(num3x3_reduce, num3x3, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            ConvBlock(in_channels, num5x5_reduce, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(num5x5_reduce, num5x5, kernel_size=5, stride=1, padding=2),\n",
    "        )\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.MaxPool2d(\n",
    "                3, stride=1, padding=1, ceil_mode=True\n",
    "            ),  # adds extra cols (as padding to cover the stride used)\n",
    "            ConvBlock(in_channels, pool_proj, kernel_size=1, stride=1, padding=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.block1(x)\n",
    "        out2 = self.block2(x)\n",
    "        out3 = self.block3(x)\n",
    "        out4 = self.block4(x)\n",
    "\n",
    "        return cat([out1, out2, out3, out4], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff79caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "class GoogleLeNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(GoogleLeNet, self).__init__()\n",
    "\n",
    "        self.conv1 = ConvBlock(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.pool1 = nn.MaxPool2d(3, stride=2, padding=0, ceil_mode=True)\n",
    "        self.conv2 = ConvBlock(64, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv3 = ConvBlock(64, 192, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(3, stride=2, padding=0, ceil_mode=True)\n",
    "\n",
    "        self.inception3A = Inception(\n",
    "            in_channels=192,\n",
    "            num1x1=64,\n",
    "            num3x3_reduce=96,\n",
    "            num3x3=128,\n",
    "            num5x5_reduce=16,\n",
    "            num5x5=32,\n",
    "            pool_proj=32,\n",
    "        )\n",
    "\n",
    "        self.inception3B = Inception(\n",
    "            in_channels=256,\n",
    "            num1x1=128,\n",
    "            num3x3_reduce=128,\n",
    "            num3x3=192,\n",
    "            num5x5_reduce=32,\n",
    "            num5x5=96,\n",
    "            pool_proj=64,\n",
    "        )\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(3, stride=2, padding=0, ceil_mode=True)\n",
    "\n",
    "        self.inception4A = Inception(\n",
    "            in_channels=480,\n",
    "            num1x1=192,\n",
    "            num3x3_reduce=96,\n",
    "            num3x3=208,\n",
    "            num5x5_reduce=16,\n",
    "            num5x5=48,\n",
    "            pool_proj=64,\n",
    "        )\n",
    "\n",
    "        self.inception4B = Inception(\n",
    "            in_channels=512,\n",
    "            num1x1=160,\n",
    "            num3x3_reduce=112,\n",
    "            num3x3=224,\n",
    "            num5x5_reduce=24,\n",
    "            num5x5=64,\n",
    "            pool_proj=64,\n",
    "        )\n",
    "\n",
    "        self.inception4C = Inception(\n",
    "            in_channels=512,\n",
    "            num1x1=128,\n",
    "            num3x3_reduce=128,\n",
    "            num3x3=256,\n",
    "            num5x5_reduce=24,\n",
    "            num5x5=64,\n",
    "            pool_proj=64,\n",
    "        )\n",
    "\n",
    "        self.inception4D = Inception(\n",
    "            in_channels=512,\n",
    "            num1x1=112,\n",
    "            num3x3_reduce=144,\n",
    "            num3x3=288,\n",
    "            num5x5_reduce=32,\n",
    "            num5x5=64,\n",
    "            pool_proj=64,\n",
    "        )\n",
    "\n",
    "        self.inception4E = Inception(\n",
    "            in_channels=528,\n",
    "            num1x1=256,\n",
    "            num3x3_reduce=160,\n",
    "            num3x3=320,\n",
    "            num5x5_reduce=32,\n",
    "            num5x5=128,\n",
    "            pool_proj=128,\n",
    "        )\n",
    "\n",
    "        self.pool4 = nn.MaxPool2d(3, stride=2, padding=0, ceil_mode=True)\n",
    "\n",
    "        self.inception5A = Inception(\n",
    "            in_channels=832,\n",
    "            num1x1=256,\n",
    "            num3x3_reduce=160,\n",
    "            num3x3=320,\n",
    "            num5x5_reduce=32,\n",
    "            num5x5=128,\n",
    "            pool_proj=128,\n",
    "        )\n",
    "\n",
    "        self.inception5B = Inception(\n",
    "            in_channels=832,\n",
    "            num1x1=384,\n",
    "            num3x3_reduce=192,\n",
    "            num3x3=384,\n",
    "            num5x5_reduce=48,\n",
    "            num5x5=128,\n",
    "            pool_proj=128,\n",
    "        )\n",
    "\n",
    "        self.pool5 = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "        self.aux4A = Auxiliary(512, num_classes)\n",
    "        self.aux4D = Auxiliary(528, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.pool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.pool2(out)\n",
    "\n",
    "        out = self.inception3A(out)\n",
    "        out = self.inception3B(out)\n",
    "        out = self.pool3(out)\n",
    "        out = self.inception4A(out)\n",
    "\n",
    "        aux1 = self.aux4A(out)\n",
    "\n",
    "        out = self.inception4B(out)\n",
    "        out = self.inception4C(out)\n",
    "        out = self.inception4D(out)\n",
    "\n",
    "        aux2 = self.aux4D(out)\n",
    "\n",
    "        out = self.inception4E(out)\n",
    "        out = self.pool4(out)\n",
    "        out = self.inception5A(out)\n",
    "        out = self.inception5B(out)\n",
    "        out = self.pool5(out)\n",
    "\n",
    "        out = torch.flatten(out, 1)  # flattent to one dim tensor\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, aux1, aux2\n",
    "\n",
    "    def get_criterion(self):\n",
    "        return nn.CrossEntropyLoss()\n",
    "\n",
    "    def get_optimizer(self, learning_rate=0.01):\n",
    "        return optim.Adam(self.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0547b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "class ModelTrainer:\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_data,\n",
    "        validation_data,\n",
    "        test_data,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        epochs,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.train_data = train_data\n",
    "        self.validation_data = validation_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def fit(self):\n",
    "        num_train_samples = len(self.train_data)\n",
    "        num_validation_samples = len(self.validation_data)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            curr_train_loss = 0\n",
    "            correct_in_train = 0\n",
    "\n",
    "            self.model.train()\n",
    "\n",
    "            for inputs, labels in self.train_data:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # set gradients to zero again, to not accumulate old gradients in the new clalculations\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # generate predictions on the current set of inputs\n",
    "                # recall that we also extract the predictions from the auxialiaries\n",
    "                # and count them in the loss calculation\n",
    "                pred, aux_pred1, aux_pred2 = self.model(inputs)\n",
    "\n",
    "                # calculate loss\n",
    "                real_loss = self.criterion(pred, labels)\n",
    "                loss_aux1 = self.criterion(aux_pred1, labels)\n",
    "                loss_aux2 = self.criterion(aux_pred2, labels)\n",
    "\n",
    "                loss = real_loss + (0.3 * loss_aux1) + (0.3 * loss_aux2)\n",
    "\n",
    "                loss.backward()  # run backpropagation\n",
    "                self.optimizer.step()  # compute the new weights\n",
    "\n",
    "                # now store correctly predicted, and loss of this iteration\n",
    "\n",
    "                # first, find the predicted class by looking for the maximum in the dimension 1\n",
    "                _, predicted = torch.max(pred.data, 1)\n",
    "\n",
    "                correct_in_train += (predicted == labels).float().sum().item()\n",
    "                curr_train_loss += (\n",
    "                    loss.data.item() * inputs.shape[0]\n",
    "                )  # multiplied with batch length\n",
    "\n",
    "            train_epoch_loss = curr_train_loss / num_train_samples\n",
    "            self.train_loss.append(train_epoch_loss)\n",
    "\n",
    "            train_acc_curr = correct_in_train / num_train_samples\n",
    "            self.train_acc.append(train_acc_curr)\n",
    "\n",
    "            # Now check trained weights on the validation set\n",
    "            val_running_loss = 0\n",
    "            correct_val = 0\n",
    "\n",
    "            self.model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in self.validation_data:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    # Forward pass.\n",
    "                    prediction, prediction_aux1, prediction_aux2 = self.model(inputs)\n",
    "\n",
    "                    # Compute the loss.\n",
    "                    real_loss = self.criterion(prediction, labels)\n",
    "                    loss_aux1 = self.criterion(prediction_aux1, labels)\n",
    "                    loss_aux2 = self.criterion(prediction_aux2, labels)\n",
    "\n",
    "                    loss = real_loss + (0.3 * loss_aux1) + (0.3 * loss_aux2)\n",
    "\n",
    "                    # Compute validation accuracy.\n",
    "                    _, predicted_outputs = torch.max(prediction.data, 1)\n",
    "                    correct_val += (predicted_outputs == labels).float().sum().item()\n",
    "\n",
    "                # Compute batch loss.\n",
    "                val_running_loss += loss.data.item() * inputs.shape[0]\n",
    "\n",
    "                val_epoch_loss = val_running_loss / num_validation_samples\n",
    "                self.val_loss.append(val_epoch_loss)\n",
    "\n",
    "                val_acc_curr = correct_val / num_validation_samples\n",
    "                self.val_acc.append(val_acc_curr)\n",
    "\n",
    "            info = \"[Epoch {}/{}]: train-loss = {:0.6f} | train-acc = {:0.3f} | val-loss = {:0.6f} | val-acc = {:0.3f}\"\n",
    "\n",
    "            print(\n",
    "                info.format(\n",
    "                    epoch + 1,\n",
    "                    self.epochs,\n",
    "                    train_epoch_loss,\n",
    "                    train_acc_curr,\n",
    "                    val_epoch_loss,\n",
    "                    val_acc_curr,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            torch.save(self.model.state_dict(), f\"{report_dir}/checkpoint_{epoch + 1}\")\n",
    "\n",
    "        torch.save(self.model.state_dict(), f\"{report_dir}/resnet-56_weights\")\n",
    "\n",
    "    def test(self):\n",
    "        num_test_samples = len(self.test_data)\n",
    "        correctly_classified = 0\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        # no gradient calculation on evaluation\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.test_data:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                pred = self.model(inputs)\n",
    "\n",
    "                _, predicted_labels = torch.max(pred.data, 1)\n",
    "\n",
    "                correctly_classified += (\n",
    "                    (predicted_labels == labels).float().sum().item()\n",
    "                )\n",
    "\n",
    "        self.test_accuracy = correctly_classified / num_test_samples\n",
    "        print(\"Test accuracy: {}\".format(self.test_accuracy))\n",
    "\n",
    "    def plot_trainning_report(self):\n",
    "        epochs = np.arange(self.epochs) + 1\n",
    "\n",
    "        plt.figure(figsize=(20, 5))\n",
    "\n",
    "        plt.subplot(121)\n",
    "\n",
    "        plt.plot(epochs, self.train_loss, \"blue\", label=\"Training Losses\")\n",
    "        plt.plot(epochs, self.val_loss, \"r\", label=\"Validation Losses\")\n",
    "\n",
    "        plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "        plt.title(\"Training and Validation Losses vs Epochs\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Losses\")\n",
    "        plt.legend()\n",
    "        plt.grid(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.subplot(122)\n",
    "\n",
    "        plt.plot(epochs, self.train_acc, \"blue\", label=\"Training Accuracies\")\n",
    "        plt.plot(epochs, self.val_acc, \"r\", label=\"Validation Accuracies\")\n",
    "\n",
    "        plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "\n",
    "        plt.title(\"Training and Validation Accuracies vs Epochs\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracies\")\n",
    "        plt.legend()\n",
    "        plt.grid(\"off\")\n",
    "        plt.savefig(f\"{report_dir}/training_classification_report.png\")\n",
    "\n",
    "    def plot_testing_report(self):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.epochs, self.test_accuracy, \"b\", label=\"Testing Accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.title(\"Testing Accuracy Over Epochs\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        plt.savefig(f\"{report_dir}/testing_classification_report.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec424493",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = GetDataset(input_dir=\"./data/raw\", batch_size=32)\n",
    "\n",
    "model = GoogleLeNet(num_classes=data.num_classes).to(device)\n",
    "\n",
    "model_trainer = ModelTrainer(\n",
    "    model=model,\n",
    "    train_data=data.train_loader,\n",
    "    validation_data=data.valid_loader,\n",
    "    test_data=data.test_loader,\n",
    "    optimizer=model.get_optimizer(),\n",
    "    criterion=model.get_criterion(),\n",
    "    epochs=15,\n",
    ")\n",
    "model_trainer.fit()\n",
    "model_trainer.plot_trainning_report()\n",
    "\n",
    "model_trainer.test()\n",
    "model_trainer.plot_testing_report()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
