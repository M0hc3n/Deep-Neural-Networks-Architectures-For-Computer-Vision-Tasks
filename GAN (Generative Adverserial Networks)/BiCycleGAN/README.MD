## BiCycle GAN:

The following, is an implementation of the latter architecture. I am also attaching a set of usefull links:

- [The Original Paper](https://arxiv.org/pdf/1711.11586)
- [Kaggle Notebook (to see the results)](https://www.kaggle.com/code/mohcenchouireb/bicyclegan-using-pytorch)
- [Original Implementation](https://github.com/junyanz/BicycleGAN/blob/master/models)
- [A deeper dive into Reparameterization Trick](https://snawarhussain.com/blog/genrative%20models/python/vae/tutorial/machine%20learning/Reparameterization-trick-in-VAEs-explained/)
- [Why is sampling not a differentiable operation ?](https://www.reddit.com/r/MLQuestions/comments/dck8qv/why_do_we_say_sampling_is_not_differentiable/)
- [Why would we want to encode the input image as a distribution over the latent space ?](https://www.reddit.com/r/MachineLearning/comments/pezqvv/discussion_whats_the_rational_behind_encoding_a/)
